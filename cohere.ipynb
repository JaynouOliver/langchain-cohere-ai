{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking everything is working fine\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking everything is working fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain[llms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cohere.Generation {\n",
      "\tid: 20025043-72ff-4a48-8a10-e7d6fb1c07c1\n",
      "\tprompt: Please explain to me how LLMs work\n",
      "\ttext:  LLMs, or Large Language Models, are a type of neural network model that has been trained on massive amounts of text data and can generate human-like responses to text input. They work by using deep learning techniques to learn the patterns and relationships in the data they are trained on, and then using that knowledge to make predictions on new, unseen data.\n",
      "\n",
      "The key component of an LLM is its attention mechanism, which allows it to focus on different parts of the input text when making predictions. This allows LLMs to generate more accurate and context-aware responses than traditional machine learning models.\n",
      "\n",
      "Another important component of LLMs is their transformer architecture, which allows them to process input data in parallel, rather than one layer at a time like traditional neural networks. This allows LLMs to process very large amounts of data much more efficiently than previous models.\n",
      "\n",
      "Overall, LLMs are an important breakthrough in the field of natural language processing and have the potential to transform many industries, including healthcare, finance, and customer service.\n",
      "\tlikelihood: None\n",
      "\tfinish_reason: COMPLETE\n",
      "\ttoken_likelihoods: None\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.Client('api_key')\n",
    "\n",
    "\n",
    "response = co.generate(\n",
    "  prompt='Please explain to me how LLMs work',\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatCohere\n",
    "from langchain.schema import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatCohere(cohere_api_key='api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Who's there?\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"knock knock\")]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=\"Who's there?\", generation_info={'documents': None}, message=AIMessage(content=\"Who's there?\"))]], llm_output={}, run=[RunInfo(run_id=UUID('9bdb48ae-9f74-461b-b24d-c17db30370c6'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat.agenerate([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who's there?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Who's there?\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatCohere(\n",
    "    cohere_api_key='api_key',\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
